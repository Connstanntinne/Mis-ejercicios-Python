{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Programació per a *Data Science*\n",
    "============================\n",
    "\n",
    "Unitat 5: Adquisició de dades en Python\n",
    "---------------------------------------\n",
    "\n",
    "Instruccions d'ús\n",
    "-----------------\n",
    "\n",
    "A continuació es presentaran explicacions i exemples d'adquisició de\n",
    "dades en Python. Recordeu que podeu anar executant els exemples per\n",
    "obtenir-ne els resultats.\n",
    "\n",
    "Introducció\n",
    "-----------\n",
    "\n",
    "Els processos d'adquisició de dades són molt diversos. En aquesta\n",
    "unitat, veurem exemples d'adquisició de dades d'internet amb tres\n",
    "mètodes diferents:\n",
    "\n",
    "-   descàrrega directa\n",
    "-   petició a APIs de tercers\n",
    "-   *web crawling*\n",
    "\n",
    "Pel que respecta a la interacció amb APIs de tercers, repassarem dues\n",
    "alternatives, la construcció manual de les peticions HTTP i l'ús de\n",
    "llibreries Python.\n",
    "\n",
    "En relació amb el _web crawling_, veurem com utilitzar la llibreria\n",
    "[Scrapy](https://scrapy.org/) per construir un petit _web\n",
    "crawler_ que capturi dades del nostre interès.\n",
    "\n",
    "### Primers passos\n",
    "\n",
    "En aquesta unitat treballarem diverses vegades amb dades en format\n",
    "JSON (recordeu que ja hem introduït el format JSON a la xwiki).\n",
    "\n",
    "La llibreria json de Python ens ofereix algunes funcions molt útils per\n",
    "a treballar en aquest format. Per exemple, podem obtenir la\n",
    "representació JSON d'objectes Python o crear objectes Python a partir de\n",
    "la seva representació en JSON."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "attributes": {
     "classes": [
      "sourceCode"
     ],
     "id": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "{'nombre': 'Yann', 'apellidos': {'apellido1': 'LeCun', 'apellido2': '-'}, 'edad': 56}\n",
      "<class 'list'>\n",
      "[1, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "# Construïm un diccionari d'exemple i mostrem el tipus de dades i el contingut de la variable.\n",
    "diccionario_ejemplo = {\"nombre\": \"Yann\", \"apellidos\": {\"apellido1\": \"LeCun\", \"apellido2\": \"-\"}, \"edad\": 56}\n",
    "print(type(diccionario_ejemplo))\n",
    "print(diccionario_ejemplo)\n",
    "\n",
    "# Construïm una llista d'exemple i mostrem el tipus de dades i el contingut de la variable.\n",
    "lista_ejemplo = [1, 2, 3]\n",
    "print(type(lista_ejemplo))\n",
    "print(lista_ejemplo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "attributes": {
     "classes": [
      "sourceCode"
     ],
     "id": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "{\"nombre\": \"Yann\", \"apellidos\": {\"apellido1\": \"LeCun\", \"apellido2\": \"-\"}, \"edad\": 56}\n",
      "<class 'str'>\n",
      "[1, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "# Importem la llibreria json.\n",
    "import json\n",
    "\n",
    "# Mostrem la representació JSON del diccionari.\n",
    "json_dict = json.dumps(diccionario_ejemplo)\n",
    "print(type(json_dict))\n",
    "print(json_dict)\n",
    "\n",
    "# Mostrem la representació JSON de la llista.\n",
    "json_list = json.dumps(lista_ejemplo)\n",
    "print(type(json_list))\n",
    "print(json_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fixeu-vos que, en ambdós casos, obtenim una cadena de caràcters que ens\n",
    "representa, en format JSON, els objectes Python. Aquest procés es coneix\n",
    "com a **serialitzar** l'objecte.\n",
    "\n",
    "També podem fer el procés invers (conegut com a **desserialitzar**), creant\n",
    "objectes Python (per exemple, llistes o diccionaris) a partir de cadenes\n",
    "de text en format JSON."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "attributes": {
     "classes": [
      "sourceCode"
     ],
     "id": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "{'nombre': 'Yann', 'apellidos': {'apellido1': 'LeCun', 'apellido2': '-'}, 'edad': 56}\n",
      "<class 'list'>\n",
      "[1, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "# Desserialitzem la cadena 'json_dict'.\n",
    "diccionario_ejemplo2 = json.loads(json_dict)\n",
    "print(type(diccionario_ejemplo2))\n",
    "print(diccionario_ejemplo2)\n",
    "\n",
    "# Desserialitzem la cadena 'json_list'.\n",
    "lista_ejemplo2 = json.loads(json_list)\n",
    "print(type(lista_ejemplo2))\n",
    "print(lista_ejemplo2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per millorar la llegibilitat de les dades que obtindrem de les APIs,\n",
    "definirem una funció que mostrarà cadenes JSON per pantalla formatades\n",
    "per millorar-ne la lectura. La funció acceptarà tant cadenes de\n",
    "caràcters amb contingut JSON com objectes Python, i mostrarà el\n",
    "contingut per pantalla.\n",
    "\n",
    "A més, la funció rebrà un paràmetre opcional que ens permetrà indicar el\n",
    "nombre màxim de línies que cal mostrar. Així, podrem fer servir la funció per\n",
    "a visualitzar les primeres línies d'un JSON llarg, sense haver de\n",
    "mostrar el JSON complet per pantalla."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "attributes": {
     "classes": [
      "sourceCode"
     ],
     "id": ""
    }
   },
   "outputs": [],
   "source": [
    "# Defineix la funció 'json_print', que té un paràmetre obligatori 'json_data' i un paràmetre opcional 'limit'\n",
    "# i no torna cap valor.\n",
    "# La funció mostra per pantalla el contingut de la variable 'json_data' en format JSON, limitant el nombre \n",
    "# de línies per mostrar si s'inclou el paràmetre 'limit'.\n",
    "def json_print (json_data, limit = None):\n",
    "    if isinstance(json_data, (str)):\n",
    "        json_data = json.loads(json_data)\n",
    "    nice = json.dumps(json_data, sort_keys=True, indent=3, separators=(',', ': '))\n",
    "    print(\"\\n\".join(nice.split(\"\\n\")[0:limit]))\n",
    "    if limit is not None:\n",
    "        print(\"[...]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vegem un exemple del resultat d'utilitzar la funció que acabem de\n",
    "definir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "attributes": {
     "classes": [
      "sourceCode"
     ],
     "id": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"nombre\": \"Yann\", \"apellidos\": {\"apellido1\": \"LeCun\", \"apellido2\": \"-\"}, \"edad\": 56}\n"
     ]
    }
   ],
   "source": [
    "# Mostra el valor de la variable 'json_exemple' amb la funció 'print'.\n",
    "json_exemple = '{\"nombre\": \"Yann\", \"apellidos\": {\"apellido1\": \"LeCun\", \"apellido2\": \"-\"}, \"edad\": 56}'\n",
    "print(json_exemple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "attributes": {
     "classes": [
      "sourceCode"
     ],
     "id": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "   \"apellidos\": {\n",
      "      \"apellido1\": \"LeCun\",\n",
      "      \"apellido2\": \"-\"\n",
      "   },\n",
      "   \"edad\": 56,\n",
      "   \"nombre\": \"Yann\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Mostra el valor de la variable 'json_exemple' amb la funció 'json_print' que acabem de definir.\n",
    "json_print(json_exemple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "attributes": {
     "classes": [
      "sourceCode"
     ],
     "id": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "   \"apellidos\": {\n",
      "      \"apellido1\": \"LeCun\",\n",
      "[...]\n"
     ]
    }
   ],
   "source": [
    "# Mostrem únicament les tres primeres línies.\n",
    "json_print(json_exemple, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descàrrega directa de dades\n",
    "\n",
    "La descàrrega directa del conjunt de dades és potser el mètode més\n",
    "senzill d'adquisició de dades i consisteix a descarregar un fitxer amb\n",
    "les dades d'interès ja recopilades per algun altre analista. De fet, a\n",
    "la unitat anterior ja hem fet servir aquest mètode per adquirir el\n",
    "fitxer amb les dades sobre els personatges de còmic de Marvel. Un cop\n",
    "descarregat el fitxer, el procediment per carregar-lo en Python dependrà\n",
    "del format concret (ja hem vist un exemple de càrrega de dades des d'un\n",
    "fitxer .csv).\n",
    "\n",
    "Alguns dels llocs web on podeu trobar conjunts de dades a analitzar són:\n",
    "- [Open Data gencat](http://dadesobertes.gencat.cat/en/), el portal de\n",
    "dades obertes de la Generalitat.\n",
    "- [datos.gov.es](http://datos.gob.es/es/catalogo), el catàleg de conjunts\n",
    "de dades del Govern d'Espanya. \n",
    "- [European Data\n",
    "Sources](https://data.europa.eu/), el portal de dades obertes de la Unió\n",
    "Europea. \n",
    "- [Mark Newman network\n",
    "datasets](http://www-personal.umich.edu/~mejn/netdata/), conjunts de\n",
    "dades en forma de xarxa recopilats per Mark Newman. \n",
    "- [Stanford Large\n",
    "Network Dataset Collection](http://snap.stanford.edu/data/), un altre\n",
    "recopilatori de conjunts de dades en forma de xarxa, en aquest cas creat\n",
    "per Jure Leskovec. \n",
    "- [SecRepo.com](http://www.secrepo.com/), dades\n",
    "relacionades amb la seguretat. \n",
    "- [AWS Public\n",
    "Datasets](https://aws.amazon.com/public-datasets/), conjunts de dades\n",
    "recopilades i hostatjades per Amazon. \n",
    "- [UC Irvine Machine Learning\n",
    "Repository](http://archive.ics.uci.edu/ml/), dades recopilades per un\n",
    "grup de recerca de la Universitat de Califòrnia, Irvine. \n",
    "- El\n",
    "[repositori de Five Thirty Eight](https://github.com/fivethirtyeight),\n",
    "que recull dades utilitzades a articles de la publicació i que ja hem\n",
    "vist a la unitat anterior.\n",
    "\n",
    "Ús d'API de tercers\n",
    "--------------------\n",
    "\n",
    "### Accés a API manualment\n",
    "\n",
    "Podem utilitzar la llibreria de Python\n",
    "[Requests](http://docs.python-requests.org/) per a realitzar\n",
    "peticions als webs API de manera manual. Per fer-ho, haurem d'accedir\n",
    "a la documentació de l'API amb la qual vulguem actuar, construir\n",
    "manualment les peticions per obtenir la informació desitjada i processar\n",
    "també manualment la resposta rebuda.\n",
    "\n",
    "Vegem un exemple de petició HTTP a una API pública. El lloc\n",
    "http://postcodes.io/ ofereix una API de geolocalització sobre codis\n",
    "postals al Regne Unit. Llegint la documentació, podem veure que té un\n",
    "mètode GET amb la URL\n",
    "http://api.postcodes.io/postcodes/:código-postal,\n",
    "que ens retorna informació del codi postal especificat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "attributes": {
     "classes": [
      "sourceCode"
     ],
     "id": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Codi d'estat de la resposta:  200 \n",
      "\n",
      "Capçalera de la resposta: \n",
      "{\n",
      "   \"Access-Control-Allow-Origin\": \"*\",\n",
      "   \"Connection\": \"keep-alive\",\n",
      "   \"Content-Length\": \"805\",\n",
      "   \"Content-Type\": \"application/json; charset=utf-8\",\n",
      "   \"Date\": \"Mon, 05 Aug 2019 08:22:43 GMT\",\n",
      "   \"ETag\": \"W/\\\"325-s87vTpVPeXA7mcWcF8hfLWqOGL8\\\"\",\n",
      "   \"Server\": \"nginx/1.14.0\",\n",
      "   \"X-GNU\": \"Michael J Blanchard\"\n",
      "}\n",
      "\n",
      "Cos de la resposta: \n",
      "{\n",
      "   \"result\": {\n",
      "      \"admin_county\": null,\n",
      "      \"admin_district\": \"Tower Hamlets\",\n",
      "      \"admin_ward\": \"St Katharine's & Wapping\",\n",
      "      \"ccg\": \"NHS Tower Hamlets\",\n",
      "      \"ced\": null,\n",
      "      \"codes\": {\n",
      "         \"admin_county\": \"E99999999\",\n",
      "         \"admin_district\": \"E09000030\",\n",
      "         \"admin_ward\": \"E05009330\",\n",
      "         \"ccg\": \"E38000186\",\n",
      "         \"ced\": \"E99999999\",\n",
      "         \"nuts\": \"UKI42\",\n",
      "         \"parish\": \"E43000220\",\n",
      "         \"parliamentary_constituency\": \"E14000882\"\n",
      "      },\n",
      "      \"country\": \"England\",\n",
      "      \"eastings\": 534427,\n",
      "      \"european_electoral_region\": \"London\",\n",
      "      \"incode\": \"1TT\",\n",
      "      \"latitude\": 51.508024,\n",
      "      \"longitude\": -0.064393,\n",
      "      \"lsoa\": \"Tower Hamlets 026B\",\n",
      "      \"msoa\": \"Tower Hamlets 026\",\n",
      "      \"nhs_ha\": \"London\",\n",
      "      \"northings\": 180564,\n",
      "      \"nuts\": \"Tower Hamlets\",\n",
      "      \"outcode\": \"E98\",\n",
      "      \"parish\": \"Tower Hamlets, unparished area\",\n",
      "      \"parliamentary_constituency\": \"Poplar and Limehouse\",\n",
      "      \"postcode\": \"E98 1TT\",\n",
      "      \"primary_care_trust\": \"Tower Hamlets\",\n",
      "      \"quality\": 1,\n",
      "      \"region\": \"London\"\n",
      "   },\n",
      "   \"status\": 200\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Importem la llibreria.\n",
    "import requests\n",
    "\n",
    "# Fem una petició get a l'API, preguntant sobre el codi postal \"E98 1TT\".\n",
    "# Fixeu-vos que el caràcter espai es codifica com a% 20 a la URL.\n",
    "response = requests.get('http://api.postcodes.io/postcodes/E98%201TT')\n",
    "\n",
    "# Mostrem la resposta rebuda.\n",
    "print(\"Codi d'estat de la resposta: \", response.status_code, \"\\n\")\n",
    "print(\"Capçalera de la resposta: \")\n",
    "json_print(dict(response.headers))\n",
    "print(\"\\nCos de la resposta: \")\n",
    "json_print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com podem veure, l'estat de la resposta és 200, la qual cosa [ens\n",
    "indica](https://www.w3.org/Protocols/rfc2616/rfc2616-sec10.html) que la\n",
    "petició s'ha processat correctament. Entre d'altres camps, la capçalera\n",
    "de la resposta inclou el tipus de contingut que trobarem al cos, que\n",
    "serà un text en format JSON. Finalment, el cos de la resposta inclou\n",
    "dades sobre el codi postal consultat. Per exemple, podem veure que\n",
    "correspon a la nació d'Anglaterra (concretament, a la ciutat de\n",
    "Londres).\n",
    "\n",
    "Fixeu-vos que podem visualitzar també la resposta accedint a la [mateixa\n",
    "URL](http://api.postcodes.io/postcodes/E98%201TT) amb un navegador web.\n",
    "En aquest cas, es poden instal·lar extensions específiques que gestionin\n",
    "la visualització millorada del JSON retornat (per exemple,\n",
    "[JSONView](https://chrome.google.com/webstore/detail/jsonview/chklaanhfefbnpoihckbnefhakgolnmc)\n",
    "per Chrome o Firefox).\n",
    "\n",
    "### Accés a API amb llibreries de Python\n",
    "\n",
    "Encara que podríem fer servir aquest mètode per interactuar amb\n",
    "qualsevol API HTTP, la veritat és que quan la complexitat de les\n",
    "funcions disponibles incrementa (per exemple, en incloure autenticació)\n",
    "pot no resultar gaire pràctic. Quan vulguem accedir a APIs populars,\n",
    "normalment trobarem que ja existeixen llibreries de Python dissenyades\n",
    "per interactuar amb aquestes API, de manera que podrem obtenir dades\n",
    "sense necessitat de gestionar les peticions HTTP manualment.\n",
    "\n",
    "Per exemple, Twitter, la famosa plataforma d'enviament de missatges curts, ofereix diverses [APIs](https://developer.twitter.com/en/docs/api-reference-index) que permeten obtenir dades de la xarxa. Disposem de diverses llibreries de Python que permeten interactuar amb l'API de Twitter. En aquest notebook, veurem com obtenir dades de Twitter fent servir [Tweepy](http://www.tweepy.org/).\n",
    "\n",
    "#### Autenticació amb l'API de Twitter\n",
    "\n",
    "Twitter requereix autenticació per a poder utilitzar la seva API. Per aquest motiu, el primer pas a realitzar per poder obtenir dades de Twitter a través de la seva API és aconseguir unes credencials adequades. En aquesta secció, descriurem com obtenir credencials per accedir a l'API de Twitter.\n",
    "\n",
    "Per començar, cal disposar d'un compte a Twitter. Per poder executar els exemples de l'notebook, necessitareu per tant tenir un compte de Twitter. Podeu utilitzar el vostre compte personal, si ja en disposeu d'un, per a sol·licitar els permisos de desenvolupador que ens permetran interactuar amb l'API. En cas contrari (o si preferiu no fer servir vostre compte personal), podeu crear-vos un compte de Twitter nou. El procés és molt senzill:\n",
    "1. Accedir a [Twitter] (http://www.twitter.com).\n",
    "2. Prémer sobre *Sign up for Twitter* i seguir les indicacions per completar el registre.\n",
    "\n",
    "Després, caldrà sol·licitar convertir el compte recent creat (o el vostre compte personal), en un compte de desenvolupador. Per fer-ho, cal seguir els següents passos:\n",
    "1. Accedir al [panell de desenvolupadors de Twitter](https://developer.twitter.com/).\n",
    "2. Clickar sobre *Apply*.\n",
    "3. Cliqueu sobre *Apply for a developer account*.\n",
    "3. Prémer *Continue*.\n",
    "4. Indicar per què voleu disposar d'un compte de desenvolupador.\n",
    "\n",
    "Per poder realitzar aquest procés satisfactòriament, necessitareu que el vostre compte disposi d'un número de telèfon associat verificat. En cas contrari, veureu que us apareixerà un missatge perquè verifiqueu el vostre telèfon.\n",
    "\n",
    "Finalment, un cop ja disposem d'un compte a Twitter, serà necessari realitzar una nova aplicació. Per fer-ho, cal seguir els següents passos:\n",
    "1. Accedir al [panell de desenvolupadors de Twitter](https://developer.twitter.com/en/apps).\n",
    "2. Prémer sobre *Create new app*.\n",
    "3. Omplir el formulari amb els detalls de l'aplicació. En concret, necessitareu proporcionar com a mínim els camps:\n",
    "    * *App name*\n",
    "    * *Application description*\n",
    "    * *Website URL*\n",
    "    * *Tell us how this app will be used*\n",
    "\n",
    "El camp Website ha de contenir una URL vàlida (per exemple, l'enllaç al vostre perfil de Twitter).\n",
    "\n",
    "Un cop creada l'aplicació, podeu accedir a la pestanya *Keys and access tokens*. Allà es troben les credencials acabades de crear per la vostra aplicació, que farem servir per autenticar i poder utilitzar l'API de Twitter. Veureu que ja teniu les claus *Consumer API keys* disponibles. A més, serà necessari prémer sobre *Create* a la secció *Access token & access token secret* per obtenir també tots dos tokens. Els quatre valors seran usats per autenticar la nostra aplicació:\n",
    "* API / Consumer Key\n",
    "* API / Consumer Secret\n",
    "* Access Token\n",
    "* Access Token Secret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### La llibreria Tweepy\n",
    "\n",
    "[Tweepy](http://www.tweepy.org/) ens permet interactuar amb l'API de Twitter d'una manera senzilla, ja que encapsula els mètodes HTTP de l'API en mètodes de Python, que poden ser cridats directament. Trobareu la documentació de la llibreria en el següent [enllaç](http://tweepy.readthedocs.io)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El tipus de dades de la variable user és: <class 'tweepy.models.User'>\n",
      "El nom d'usuari és: Twitter\n",
      "L'id d'usuari és: 783214\n"
     ]
    }
   ],
   "source": [
    "# Importem la llibreria tweepy\n",
    "import tweepy\n",
    "\n",
    "# IMPORTANT: És necessari inclore les credencials d'accés que hagueu obtingut\n",
    "# per executar l'exemple \n",
    "consumer_key = ''\n",
    "consumer_secret = ''\n",
    "access_token = ''\n",
    "access_secret = ''\n",
    "\n",
    "# Inicialitzem la interacció amb l'API\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_secret)\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "# Obtenim dades de l'usuari \"twitter\" fent servir la llibreria tweepy\n",
    "user = api.get_user('twitter')\n",
    "\n",
    "print(\"El tipus de dades de la variable user és: {}\".format(type(user)))\n",
    "print(\"El nom d'usuari és: {}\".format(user.screen_name))\n",
    "print(\"L'id d'usuari és: {}\".format(user.id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fixeu-vos que, en aquest cas, no hem hagut de gestionar les peticions HTTP manualment: la llibreria ho ha fet per nosaltres de forma transparent.\n",
    "\n",
    "A més, les funcions de la llibreria ens tornen directament objectes Python, que poden ser usats com qualsevol altre. Per exemple, podem seleccionar només una part de les respostes de les APIs segons el nostre interès (en l'exemple anterior, hem seleccionat l'identificador i el nom d'usuari directament usant l'objecte `user`). Vegem alguns exemples més d'atributs que hem recuperat de l'usuari:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El número de seguidors és: 56440837\n",
      "El número d'amics és: 29\n",
      "El número de tweets és: 11114\n"
     ]
    }
   ],
   "source": [
    "# Mostramos algunos atributos del usuario recuperado\n",
    "print(\"El número de seguidors és: {}\".format(user.followers_count))\n",
    "print(\"El número d'amics és: {}\".format(user.friends_count))\n",
    "print(\"El número de tweets és: {}\".format(user.statuses_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Capturant les dades manualment: *web crawling*\n",
    "------------------------------------------\n",
    "\n",
    "[Scrapy](https://scrapy.org/) és una llibreria de Python que proveeix d'un\n",
    "_framework_ per a l'extracció de dades de pàgines web. Scrapy és molt\n",
    "complet i disposa de múltiples funcionalitats, però en veurem un exemple\n",
    "senzill d'ús.\n",
    "\n",
    "Suposeu que volem obtenir un llistat de les titulacions de grau que\n",
    "ofereix la UOC. La UOC no ofereix una API amb aquesta informació, però\n",
    "sí que podem trobar-la a la pàgina <http://estudios.uoc.edu/es/grados>.\n",
    "De totes maneres, no volem anar copiant manualment els noms de totes les\n",
    "titulacions per obtenir el llistat d'interès, per la qual cosa\n",
    "desenvoluparem un petit _crawler_ que obtingui aquestes dades per\n",
    "nosaltres.\n",
    "\n",
    "Ja tenim identificada la URL que volem explorar\n",
    "(<http://estudios.uoc.edu/es/grados>), així que només caldrà identificar\n",
    "on es troben les dades d'interès dins de la pàgina. Per fer-ho, en\n",
    "primer lloc ens fixarem en algun títol de grau que aparegui a la pàgina,\n",
    "per exemple, \"Diseño y Creación Digitales\" o \"Multimedia\". Seguidament\n",
    "accedirem al codi font de la pàgina (podem fer servir la combinació de\n",
    "tecles `CTRL + u` als navegadors Firefox o Chrome) i buscarem els noms\n",
    "dels graus que hem vist anteriorment:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "<a \n",
    "   title=\"Diseño y Creación Digitales\" \n",
    "   href=\"/es/grados/diseño-creacion-digital/presentacion\" \n",
    "   class=\"card-absolute-link\">\n",
    "    &nbsp;\n",
    "</a>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "<a \n",
    "   title=\"Multimedia\" \n",
    "   href=\"/es/grados/multimedia/presentacion\" \n",
    "   class=\"card-absolute-link\">\n",
    "    &nbsp;\n",
    "</a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com es pot apreciar, les dades que volem recopilar (els noms de les\n",
    "titulacions de grau que ofereix la UOC) es troben a l'atribut títol\n",
    "(*title*) d'un enllaç (un element assenyalat amb l'etiqueta `<a>`) que\n",
    "té l'atribut classe fixat a «card-absolute-link».\n",
    "\n",
    "Per a indicar que volem seleccionar aquestes dades, utilitzarem la\n",
    "sintaxi XPath. En concret, utilitzarem l'expressió"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "//a[@class=\"card-absolute-link\"]/@title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "que ens indica que volem seleccionar totes les etiquetes `<a>` que\n",
    "tinguin com a atribut classe el valor «card-absolute-link» i\n",
    "extreure'n el títol. Amb això ja podem programar la nostra aranya\n",
    "perquè n'extregui les dades d'interès.\n",
    "\n",
    "L'estructura d'un _crawler_ amb Scrapy ve prefixada. En el nostre cas,\n",
    "només serà necessari definir una aranya i incloure un _parser_ que\n",
    "extregui les dades de les titulacions i que disposi de l'URL d'inici."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "attributes": {
     "classes": [
      "sourceCode"
     ],
     "id": ""
    }
   },
   "outputs": [],
   "source": [
    "# Importem Scrapy.\n",
    "import scrapy\n",
    "from scrapy.crawler import CrawlerProcess\n",
    "\n",
    "# Creem l'aranya.\n",
    "class uoc_spider(scrapy.Spider):\n",
    "\n",
    "    # Assignem un nom a l'aranya.\n",
    "    name = \"uoc_spider\"\n",
    "\n",
    "    # Indiquem l'URL que volem analitzar en primer lloc.\n",
    "    start_urls = [\n",
    "        \"http://estudios.uoc.edu/es/grados\"\n",
    "    ]\n",
    "\n",
    "    # Definim l'analitzador.\n",
    "    def parse(self, response):\n",
    "            # Extraiem el títol del grau.\n",
    "        for grado in response.xpath('//a[@class=\"card-absolute-link\"]/@title'):\n",
    "            yield {\n",
    "                'title': grado.extract()\n",
    "            }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un cop definida l'aranya, llançarem el _crawler_ indicant que volem que\n",
    "usi l'aranya `uoc_spider` que acabem de definir:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "attributes": {
     "classes": [
      "sourceCode"
     ],
     "id": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-08-05 10:22:44 [scrapy.utils.log] INFO: Scrapy 1.7.3 started (bot: scrapybot)\n",
      "2019-08-05 10:22:44 [scrapy.utils.log] INFO: Versions: lxml 4.4.0.0, libxml2 2.9.9, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.8 (default, Jan 14 2019, 11:02:34) - [GCC 8.0.1 20180414 (experimental) [trunk revision 259383]], pyOpenSSL 19.0.0 (OpenSSL 1.1.1  11 Sep 2018), cryptography 2.1.4, Platform Linux-4.15.0-55-generic-x86_64-with-Ubuntu-18.04-bionic\n",
      "2019-08-05 10:22:44 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}\n",
      "2019-08-05 10:22:45 [scrapy.extensions.telnet] INFO: Telnet Password: 996bef2c2c8b8b5a\n",
      "2019-08-05 10:22:45 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.memusage.MemoryUsage',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2019-08-05 10:22:45 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2019-08-05 10:22:45 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2019-08-05 10:22:45 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2019-08-05 10:22:45 [scrapy.core.engine] INFO: Spider opened\n",
      "2019-08-05 10:22:45 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2019-08-05 10:22:45 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023\n",
      "2019-08-05 10:22:45 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://estudios.uoc.edu/es/grados> from <GET http://estudios.uoc.edu/es/grados>\n",
      "2019-08-05 10:22:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://estudios.uoc.edu/es/grados> (referer: None)\n",
      "2019-08-05 10:22:46 [scrapy.core.scraper] DEBUG: Scraped from <200 https://estudios.uoc.edu/es/grados>\n",
      "{'title': 'Antropología y Evolución Humana (interuniversitario: URV, UOC)'}\n",
      "2019-08-05 10:22:46 [scrapy.core.scraper] DEBUG: Scraped from <200 https://estudios.uoc.edu/es/grados>\n",
      "{'title': 'Artes'}\n",
      "2019-08-05 10:22:46 [scrapy.core.scraper] DEBUG: Scraped from <200 https://estudios.uoc.edu/es/grados>\n",
      "{'title': 'Ciencias Sociales'}\n",
      "2019-08-05 10:22:46 [scrapy.core.scraper] DEBUG: Scraped from <200 https://estudios.uoc.edu/es/grados>\n",
      "{'title': 'Historia, Geografia e Historia del Arte (interuniversitario: UOC, UdL)'}\n",
      "2019-08-05 10:22:46 [scrapy.core.scraper] DEBUG: Scraped from <200 https://estudios.uoc.edu/es/grados>\n",
      "{'title': 'Humanidades'}\n",
      "2019-08-05 10:22:46 [scrapy.core.scraper] DEBUG: Scraped from <200 https://estudios.uoc.edu/es/grados>\n",
      "{'title': 'Lengua y Literatura Catalanas'}\n",
      "2019-08-05 10:22:46 [scrapy.core.scraper] DEBUG: Scraped from <200 https://estudios.uoc.edu/es/grados>\n",
      "{'title': 'Traducción, Interpretación y Lenguas Aplicadas (interuniversitario: UVic-UCC, UOC)'}\n",
      "2019-08-05 10:22:46 [scrapy.core.scraper] DEBUG: Scraped from <200 https://estudios.uoc.edu/es/grados>\n",
      "{'title': 'Logopedia (interuniversitario: Uvic-UCC, UOC)'}\n",
      "2019-08-05 10:22:46 [scrapy.core.scraper] DEBUG: Scraped from <200 https://estudios.uoc.edu/es/grados>\n",
      "{'title': 'Comunicación'}\n",
      "2019-08-05 10:22:46 [scrapy.core.scraper] DEBUG: Scraped from <200 https://estudios.uoc.edu/es/grados>\n",
      "{'title': 'Diseño y Creación Digitales'}\n",
      "2019-08-05 10:22:46 [scrapy.core.scraper] DEBUG: Scraped from <200 https://estudios.uoc.edu/es/grados>\n",
      "{'title': 'Criminología'}\n",
      "2019-08-05 10:22:46 [scrapy.core.scraper] DEBUG: Scraped from <200 https://estudios.uoc.edu/es/grados>\n",
      "{'title': 'Derecho'}\n",
      "2019-08-05 10:22:46 [scrapy.core.scraper] DEBUG: Scraped from <200 https://estudios.uoc.edu/es/grados>\n",
      "{'title': 'Doble titulación de Derecho y de Administración y Dirección de Empresas'}\n",
      "2019-08-05 10:22:46 [scrapy.core.scraper] DEBUG: Scraped from <200 https://estudios.uoc.edu/es/grados>\n",
      "{'title': 'Gestión y Administración Pública (interuniversitario: UOC, UB)'}\n",
      "2019-08-05 10:22:46 [scrapy.core.scraper] DEBUG: Scraped from <200 https://estudios.uoc.edu/es/grados>\n",
      "{'title': 'Relaciones Internacionales'}\n",
      "2019-08-05 10:22:46 [scrapy.core.scraper] DEBUG: Scraped from <200 https://estudios.uoc.edu/es/grados>\n",
      "{'title': 'Artes'}\n",
      "2019-08-05 10:22:46 [scrapy.core.scraper] DEBUG: Scraped from <200 https://estudios.uoc.edu/es/grados>\n",
      "{'title': 'Diseño y Creación Digitales'}\n",
      "2019-08-05 10:22:46 [scrapy.core.scraper] DEBUG: Scraped from <200 https://estudios.uoc.edu/es/grados>\n",
      "{'title': 'Multimedia'}\n",
      "2019-08-05 10:22:46 [scrapy.core.scraper] DEBUG: Scraped from <200 https://estudios.uoc.edu/es/grados>\n",
      "{'title': 'Administración y Dirección de Empresas'}\n",
      "2019-08-05 10:22:46 [scrapy.core.scraper] DEBUG: Scraped from <200 https://estudios.uoc.edu/es/grados>\n",
      "{'title': 'Doble titulación de Administración y Dirección de Empresas y de Turismo'}\n",
      "2019-08-05 10:22:46 [scrapy.core.scraper] DEBUG: Scraped from <200 https://estudios.uoc.edu/es/grados>\n",
      "{'title': 'Economía'}\n",
      "2019-08-05 10:22:46 [scrapy.core.scraper] DEBUG: Scraped from <200 https://estudios.uoc.edu/es/grados>\n",
      "{'title': 'Marketing e investigación de mercados'}\n",
      "2019-08-05 10:22:46 [scrapy.core.scraper] DEBUG: Scraped from <200 https://estudios.uoc.edu/es/grados>\n",
      "{'title': 'Relaciones Laborales y Ocupación'}\n",
      "2019-08-05 10:22:46 [scrapy.core.scraper] DEBUG: Scraped from <200 https://estudios.uoc.edu/es/grados>\n",
      "{'title': 'Ciencia de Datos Aplicada /Applied Data Science'}\n",
      "2019-08-05 10:22:46 [scrapy.core.scraper] DEBUG: Scraped from <200 https://estudios.uoc.edu/es/grados>\n",
      "{'title': 'Doble titulación de Ingeniería Informática y de Administración y Dirección de Empresas'}\n",
      "2019-08-05 10:22:46 [scrapy.core.scraper] DEBUG: Scraped from <200 https://estudios.uoc.edu/es/grados>\n",
      "{'title': 'Ingeniería Informática'}\n",
      "2019-08-05 10:22:46 [scrapy.core.scraper] DEBUG: Scraped from <200 https://estudios.uoc.edu/es/grados>\n",
      "{'title': 'Ingeniería de Tecnologías y Servicios de Telecomunicación'}\n",
      "2019-08-05 10:22:46 [scrapy.core.scraper] DEBUG: Scraped from <200 https://estudios.uoc.edu/es/grados>\n",
      "{'title': 'Multimedia'}\n",
      "2019-08-05 10:22:46 [scrapy.core.scraper] DEBUG: Scraped from <200 https://estudios.uoc.edu/es/grados>\n",
      "{'title': 'Educación Social'}\n",
      "2019-08-05 10:22:46 [scrapy.core.scraper] DEBUG: Scraped from <200 https://estudios.uoc.edu/es/grados>\n",
      "{'title': 'Psicología'}\n",
      "2019-08-05 10:22:46 [scrapy.core.scraper] DEBUG: Scraped from <200 https://estudios.uoc.edu/es/grados>\n",
      "{'title': 'Turismo'}\n",
      "2019-08-05 10:22:46 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2019-08-05 10:22:46 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 480,\n",
      " 'downloader/request_count': 2,\n",
      " 'downloader/request_method_count/GET': 2,\n",
      " 'downloader/response_bytes': 453717,\n",
      " 'downloader/response_count': 2,\n",
      " 'downloader/response_status_count/200': 1,\n",
      " 'downloader/response_status_count/301': 1,\n",
      " 'elapsed_time_seconds': 1.783863,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2019, 8, 5, 8, 22, 46, 991426),\n",
      " 'item_scraped_count': 31,\n",
      " 'log_count/DEBUG': 33,\n",
      " 'log_count/INFO': 10,\n",
      " 'memusage/max': 82223104,\n",
      " 'memusage/startup': 82223104,\n",
      " 'response_received_count': 1,\n",
      " 'scheduler/dequeued': 2,\n",
      " 'scheduler/dequeued/memory': 2,\n",
      " 'scheduler/enqueued': 2,\n",
      " 'scheduler/enqueued/memory': 2,\n",
      " 'start_time': datetime.datetime(2019, 8, 5, 8, 22, 45, 207563)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-08-05 10:22:46 [scrapy.core.engine] INFO: Spider closed (finished)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # Creem un crawler:\n",
    "    process = CrawlerProcess({\n",
    "        'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)',\n",
    "        'DOWNLOAD_HANDLERS': {'s3': None},\n",
    "        'LOG_ENABLED': True\n",
    "    })\n",
    "\n",
    "    # Inicialitzem el crawler amb la nostra aranya:\n",
    "    process.crawl(uoc_spider)\n",
    "\n",
    "    # Llancem l'aranya:\n",
    "    process.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'execució de Scrapy mostra un registre detallat amb tots els\n",
    "esdeveniments que han anat passant, fet que és molt útil per identificar\n",
    "problemes, sobretot en captures complexes. En el nostre cas, a més,\n",
    "podem veure com s'han extret els noms de les titulacions de grau:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "DEBUG:scrapy.core.scraper:Scraped from <200 http://estudios.uoc.edu/es/grados>\n",
    "{'title': u'Antropolog\\xeda y Evoluci\\xf3n Humana (interuniversitario: URV, UOC)'}\n",
    "DEBUG:scrapy.core.scraper:Scraped from <200 http://estudios.uoc.edu/es/grados>\n",
    "{'title': u'Ciencias Sociales'}\n",
    "DEBUG:scrapy.core.scraper:Scraped from <200 http://estudios.uoc.edu/es/grados>\n",
    "{'title': u'Historia, Geograf\\xeda e Historia del Arte (interuniversitario: UOC, UdL)'}\n",
    "DEBUG:scrapy.core.scraper:Scraped from <200 http://estudios.uoc.edu/es/grados>\n",
    "{'title': u'Humanidades'}\n",
    "DEBUG:scrapy.core.scraper:Scraped from <200 http://estudios.uoc.edu/es/grados>\n",
    "{'title': u'Lengua y Literatura Catalanas'}\n",
    "DEBUG:scrapy.core.scraper:Scraped from <200 http://estudios.uoc.edu/es/grados>\n",
    "{'title': u'Traducci\\xf3n, Interpretaci\\xf3n y Lenguas Aplicadas (interuniversitario: UVic-UCC, UOC)'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Annex: L'API de googlemaps\n",
    "\n",
    "Aquest annex conté un exemple addicional d'accés a API amb llibreries de Python. En concret, l'exemple mostra com accedir a l'API de googlemaps. En el passat, l'ús d'aquesta API era gratuït, però actualment l'ús de l'API té múltiples restriccions i, tot i que es poden fer algunes peticions gratuïtament, és necessari proporcionar dades de la nostra targeta de crèdit per poder interactuar amb l'API. Podeu revisar el codi d'aquest exemple per tenir un exemple més de l'ús de llibreries per accedir a APIs, o bé crear un compte a la plataforma de google developers i provar els exemples proporcionats. En aquest últim cas, recordeu revisar la política de cobrament de googlemaps, per assegurar que no sobrepasseu el límit gratuït, abans de realitzar les proves.\n",
    "\n",
    "Google maps disposa d'un [conjunt d'API](https://developers.google.com/maps/) molt populars que permeten,\n",
    "entre d'altres, obtenir les coordenades geogràfiques d'una adreça,\n",
    "aconseguir indicacions per desplaçar-se d'un punt a un altre, o adquirir\n",
    "dades sobre l'elevació del terreny a qualsevol punt del món. La\n",
    "llibreria\n",
    "[googlemaps](https://googlemaps.github.io/google-maps-services-python/docs/2.4.6/)\n",
    "integra peticions a l'API de Google en codi Python.\n",
    "\n",
    "Per fer servir les APIs de Google Maps, cal registrar un usuari i obtenir\n",
    "una clau d'autenticació, que adjuntarem a les peticions que es facin\n",
    "contra l'API. A més, haurem d'especificar quines APIs concretes farem\n",
    "servir.\n",
    "\n",
    "A l'exemple següent, farem aquests tres passos per obtenir la clau\n",
    "d'autenticació:\n",
    "\n",
    "1.  Crearem un projecte a la plataforma de Google Developers.\n",
    "2.  Activarem les APIs desitjades.\n",
    "3.  Sol·licitarem credencials d'accés.\n",
    "\n",
    "En primer lloc crearem un nou projecte a l'entorn de desenvolupadors de\n",
    "google. Ens dirigirem a:\n",
    "<https://console.developers.google.com/apis/library> i farem clic sobre\n",
    "«Project: New project». Assignarem un nom qualsevol al projecte i\n",
    "confirmarem la creació clicant sobre «Create».\n",
    "\n",
    "Un cop creat el projecte, activarem les APIs que farem servir. Primer,\n",
    "seleccionarem l'API de geocodificació ([*Google Maps Geocoding\n",
    "API*](https://console.developers.google.com/apis/api/geocoding_backend)),\n",
    "que es troba a la categoria *Google Maps APIs* (és possible que hagueu\n",
    "de prémer sobre el botó «more» per veure la llista completa d' APIs).\n",
    "Farem clic sobre «Enable» per activar-la.\n",
    "\n",
    "Repetirem el procés per a l'API d'adreces ([*Google Maps Directions\n",
    "API*](https://console.developers.google.com/apis/api/directions_backend)),\n",
    "que es troba també a la categoria *Google Maps APIs*.\n",
    "\n",
    "Finalment, farem clic sobre el menú «Credentials», indicarem «Create\n",
    "credentials» i escollirem «API Key». Ens apareixerà una finestra amb una\n",
    "cadena de caràcters que representa la nostra clau. Perquè l'exemple següent\n",
    "funcioni, **cal que assigneu a la variable `api_key` el valor de\n",
    "la vostra clau**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "attributes": {
     "classes": [
      "sourceCode"
     ],
     "id": ""
    }
   },
   "outputs": [
   ],
   "source": [
    "# Importem la llibreria googlemaps, que interactuarà amb l'API de Google Maps.\n",
    "import googlemaps\n",
    "\n",
    "# Importem la llibreria datetime, que ens ofereix funcions de maniobres de dates.\n",
    "from datetime import datetime\n",
    "\n",
    "####################################################################################\n",
    "# ATENCIÓ! Assigneu a la variable api_key la clau que hagueu obtingut de Google.\n",
    "api_key = \"\"\n",
    "####################################################################################\n",
    "\n",
    "# Inicialitzem el client, indicant la clau d'autenticació,\n",
    "gmaps = googlemaps.Client(key=api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En primer lloc, farem servir l'[API de\n",
    "geocodificació](https://developers.google.com/maps/documentation/geocoding/start)\n",
    "per obtenir dades d'una adreça per mitjà del mètode\n",
    "[Geocode](https://googlemaps.github.io/google-maps-services-python/docs/2.4.6/#googlemaps.Client.geocode)\n",
    "del client de Google Maps que ens ofereix la llibreria (emmagatzemat a\n",
    "la variable `gmaps`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [
      "sourceCode"
     ],
     "id": ""
    }
   },
   "outputs": [    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ Resultat de geocode ------\n",
      "[\n",
      "   {\n",
      "      \"address_components\": [\n",
      "         {\n",
      "            \"long_name\": \"156\",\n",
      "            \"short_name\": \"156\",\n",
      "            \"types\": [\n",
      "               \"street_number\"\n",
      "            ]\n",
      "         },\n",
      "         {\n",
      "            \"long_name\": \"Rambla del Poblenou\",\n",
      "            \"short_name\": \"Rambla del Poblenou\",\n",
      "            \"types\": [\n",
      "               \"route\"\n",
      "            ]\n",
      "         },\n",
      "         {\n",
      "            \"long_name\": \"Barcelona\",\n",
      "            \"short_name\": \"Barcelona\",\n",
      "[...]\n"
     ]
    }],
   "source": [
    "# Utilitzem l'API de geocodificació per obtenir dades d'una adreça.\n",
    "geocode_result = gmaps.geocode('Rambla del Poblenou, 156, Barcelona')\n",
    "print(\"------ Resultat de geocode ------\")\n",
    "json_print(geocode_result, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un altre exemple de l'ús de l'[API de geocodificació](https://developers.google.com/maps/documentation/geocoding/start)\n",
    "utilitza el mètode\n",
    "[reverse_geocode](https://googlemaps.github.io/google-maps-services-python/docs/2.4.6/#googlemaps.Client.reverse_geocode)\n",
    "per obtenir informació sobre unes coordenades geogràfiques concretes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [ {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ Resultat de reverse geocode ------\n",
      "[\n",
      "   {\n",
      "      \"address_components\": [\n",
      "         {\n",
      "            \"long_name\": \"17\",\n",
      "            \"short_name\": \"17\",\n",
      "            \"types\": [\n",
      "               \"street_number\"\n",
      "            ]\n",
      "         },\n",
      "         {\n",
      "            \"long_name\": \"Avinguda del Canal Ol\\u00edmpic\",\n",
      "            \"short_name\": \"Av. del Canal Ol\\u00edmpic\",\n",
      "            \"types\": [\n",
      "               \"route\"\n",
      "            ]\n",
      "         },\n",
      "         {\n",
      "            \"long_name\": \"Castelldefels\",\n",
      "            \"short_name\": \"Castelldefels\",\n",
      "[...]\n"
     ]
    }],
   "source": [
    "# Obtenim dades sobre unes coordenades geogràfiques.\n",
    "reverse_geocode_result = gmaps.reverse_geocode((41.2768089, 1.9884642))\n",
    "print(\"------ Resultat de reverse geocode ------\")\n",
    "json_print(reverse_geocode_result, 20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'exemple següent interactua amb l'[API d'adreces](https://developers.google.com/maps/documentation/directions/)\n",
    "fent servir el mètode\n",
    "[_directions_](https://googlemaps.github.io/google-maps-services-python/docs/2.4.6/#googlemaps.Client.directions)\n",
    "de la llibreria googlemaps de Python, per obtenir indicacions de\n",
    "desplaçament entre dos punts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [
      "sourceCode"
     ],
     "id": ""
    }
   },
   "outputs": [{
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ Resultat de directions ------\n",
      "[\n",
      "   {\n",
      "      \"bounds\": {\n",
      "         \"northeast\": {\n",
      "            \"lat\": 41.98102,\n",
      "            \"lng\": 2.817006\n",
      "         },\n",
      "         \"southwest\": {\n",
      "            \"lat\": 41.481153,\n",
      "            \"lng\": 2.014348\n",
      "         }\n",
      "      },\n",
      "      \"copyrights\": \"Map data \\u00a92017 Google, Inst. Geogr. Nacional\",\n",
      "      \"legs\": [\n",
      "         {\n",
      "[...]\n"
     ]
    }],
   "source": [
    "# Obtenim indicacions sobre com anar d'una adreça a una altra, considerant el trànsit del moment actual.\n",
    "now = datetime.now()\n",
    "directions_result = gmaps.directions(\"Carrer Colom, 114, Terrassa\",\n",
    "                                     \"Carrer Sant Antoni, 1, Salt\",\n",
    "                                     mode=\"transit\",\n",
    "                                     departure_time=now)\n",
    "print(\"------ Resultat de directions ------\")\n",
    "json_print(directions_result, 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fixeu-vos que, en aquest cas, no hem hagut de gestionar les peticions\n",
    "HTTP manualment: la llibreria ho ha fet per nosaltres de manera\n",
    "transparent.\n",
    "\n",
    "A més, les funcions de la llibreria ens tornen directament objectes\n",
    "Python, que es poden fer servir com qualsevol altre. Per exemple, podem\n",
    "seleccionar només una part de les respostes de les API segons el nostre\n",
    "interès:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [
      "sourceCode"
     ],
     "id": ""
    }
   },
   "outputs": [ {
     "data": {
      "text/plain": [
       "[u'geometry',\n",
       " u'address_components',\n",
       " u'place_id',\n",
       " u'formatted_address',\n",
       " u'types']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }],
   "source": [
    "# Mostrem les claus del diccionari que retorna la crida a geocode.\n",
    "geocode_result[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [
      "sourceCode"
     ],
     "id": ""
    }
   },
   "outputs": [{
     "data": {
      "text/plain": [
       "{u'lat': 41.4063554, u'lng': 2.1947451}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }],
   "source": [
    "# Mostrem únicament les coordenades geogràfiques de la direcció d'interès.\n",
    "geocode_result[0][\"geometry\"][\"location\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [
      "sourceCode"
     ],
     "id": ""
    }
   },
   "outputs": [{
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'lat': 41.2772149, u'lng': 1.9892062} Av. del Canal Olímpic, 17, 08860 Castelldefels, Barcelona, Spain\n",
      "{u'lat': 41.2800161, u'lng': 1.9766294} Castelldefels, Barcelona, Spain\n",
      "{u'lat': 41.2790599, u'lng': 1.9734743} Castelldefels, Barcelona, Spain\n",
      "{u'lat': 41.2792267, u'lng': 1.9636914} 08860 Sitges, Barcelona, Spain\n",
      "{u'lat': 41.3847492, u'lng': 1.949021} El Baix Llobregat, Barcelona, Spain\n",
      "{u'lat': 41.383401, u'lng': 2.027319} Barcelona Metropolitan Area, Barcelona, Spain\n",
      "{u'lat': 41.3850477, u'lng': 2.1733131} Barcelona, Spain\n",
      "{u'lat': 41.5911589, u'lng': 1.5208624} Catalonia, Spain\n",
      "{u'lat': 40.46366700000001, u'lng': -3.74922} Spain\n"
     ]
    }],
   "source": [
    "# Mostrem les localitzacions properes a les coordenades geogràfiques que hem preguntat amb 'reverse_geocode', \n",
    "# tot imprimint-ne les coordenades exactes i l'adreça.\n",
    "for result in reverse_geocode_result:\n",
    "    print(result[\"geometry\"][\"location\"], result[\"formatted_address\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [
      "sourceCode"
     ],
     "id": ""
    }
   },
   "outputs": [    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'text': u'112 km', u'value': 112026}\n"
     ]
    }],
   "source": [
    "# Mostrem únicament la distància del trajecte entre els dos punts preguntats a l'API d'adreces.\n",
    "print(directions_result[0][\"legs\"][0][\"distance\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
